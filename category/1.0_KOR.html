---
layout: default
title: 1.0 (한국어)
---

<!-- JSON-LD markup generated by Google Structured Data Markup Helper. -->
<script type="application/ld+json">
[ {
  "@context" : "http://schema.org",
  "@type" : "Dataset",
  "name" : "KorQuAD: Korean Question Answering Dataset for Machine Comprehension",
  "description" : "KorQuAD is a large-scale Korean dataset for extractive machine   reading comprehension task. There are 70,000+ human generated question-answer pairs   on Korean Wikipedia articles.",
  "version" : "1.0",
  "distribution" : {
    "@type" : "DataDownload",
    "encodingFormat" : "JSON",
    "contentUrl" : "https://korquad.github.io/dataset/KorQuAD_v1.0_train.json"
  },
  "sourceOrganization" : "LG CNS AI Big data Research Team"
}, {
  "@context" : "http://schema.org",
  "@type" : "Dataset",
  "name" : "KorQuAD: Korean Question Answering Dataset for Machine Comprehension",
  "description" : "KorQuAD is a large-scale Korean dataset for extractive machine   reading comprehension task. There are 70,000+ human generated question-answer pairs   on Korean Wikipedia articles.",
  "version" : "1.0",
  "distribution" : {
    "@type" : "DataDownload",
    "encodingFormat" : "JSON",
    "contentUrl" : "https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json"
  },
  "sourceOrganization" : "LG CNS AI Big data Research Team"
} ]
</script>

    <main style="background-color:#eee">
    <div class="cover" style="background-color:#fc766aff">
    <div class="container">
      <br>
      <h1 class="header center white-text" style="font-size: 7.3em"><img src="https://user-images.githubusercontent.com/42794980/64084950-c82b0200-cd6a-11e9-9f47-dca74e35f535.png" width="60%" alt="KorQuAD 1.0"></h1>
      <h5 class="header center white-text" style="font-size: 2em"><p>The Korean Question Answering Dataset</p></h5>
      <br><br>
    </div>
  </div>
        

  <div class="container">
    <div class="section">

      <!--   Icon Section   -->
      <div class="row">
        <div class="col s12 m5">
          <div class="icon-block" style="background-color : white">
            <br>
            <h5 class="left-down">What is KorQuAD 1.0?</h5>
            <hr style="border:solid 2px #e0e0e0"></hr>
            <br>
            <p class="light">KorQuAD 1.0은 한국어 Machine Reading Comprehension을 위해 만든 데이터셋입니다. 모든 질의에 대한 답변은 해당 Wikipedia article 문단의 일부 하위 영역으로 이루어집니다. Stanford Question Answering Dataset(SQuAD) v1.0과 동일한 방식으로 구성되었습니다.</p>
            <br>
            <div class="center">
              <a id="slideshare" href="https://www.slideshare.net/SeungyoungLim/korquad-introduction" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff" download=""><i class="material-icons left">slideshow</i>KorQuAD 1.0 소개 (Slide)</a>
            </div>
            <br>
            <div class="center">
              <a id="paper" href="http://m.dbpia.co.kr/Journal/ArticleDetail/NODE07613668" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff" download=""><i class="material-icons left">library_books</i>KorQuAD 1.0 소개 (Paper)</a>
            </div>
            <br><br><br>
            <h5 class="left-down">Getting Started</h5>
            <hr style="border:solid 2px #e0e0e0"></hr>
            <br>
            <p class="light">KorQuAD 1.0의 전체 데이터는 1,560 개의 Wikipedia article에 대해 10,645 건의 문단과 66,181 개의 질의응답 쌍으로, Training set 60,407 개, Dev set 5,774 개의 질의응답쌍으로 구분하였습니다.</p>
            <br>
            <div class="center">
              <a id="trainingset" href="/dataset/KorQuAD_v1.0_train.json" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff" download=""><i class="material-icons left">file_download</i>Training Set (37MB)</a>
            </div>
            <br>
            <div class="center">
              <a id="devset" href="/dataset/KorQuAD_v1.0_dev.json" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff" download=""><i class="material-icons left" width="100">file_download</i>Dev Set (3.9MB)</a>
            </div>
            <br>
            <p class="light">
              모델을 평가하기 위한 공식적인 evaluation script와 입력 샘플 prediction 파일을 제공합니다. 평가를 실행하려면 <code>python evaluate-korquad_v1.0.py [path_to_dev-v1.0] [path_to_predictions]</code> 를 입력하세요.
            </p>
            <br>
            <div class="center">
              <a id="evascript" href="/dataset/evaluate-v1.0.py" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff" download=""><i class="material-icons left">file_download</i>Evaluation Script</a>
            </div>
            <br>
            <div class="center">
              <a id="sampleprediction" href="/dataset/dev-evaluate-in1" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff"><i class="material-icons left" width="100">file_download</i>Sample Prediction File</a>
            </div>
            <br>
            <p class="light">
              Dev set에 대해 만족하는 모델을 만들었다면 공식 점수를 얻고 leaderboard에 올리기 위해 모델을 제줄하세요. 테스트 결과의 무결성을 위하여 Test set은 공개되지 않습니다. 대신 모델을 제출하여 Test set에서 실행할 수 있도록 해야 합니다. 다음은 모델의 공식적인 평가를 위한 과정 안내 튜토리얼입니다.
            </p>
            <br>
            <div class="center">
              <a id="tutorial" target="_blank" href="https://worksheets.codalab.org/worksheets/0x7b06f2ebd0584748a3a281018e7d19b0/" class="waves-effect waves-light btn" style="width:300px; background-color:#fc766aff">Submission Tutorial</a>
          </div>
          <br><br><br>
        </div>
      </div>

        <div class="col s12 m7">
          <div class="icon-block" style="background-color : white">
            <br>
            <h5 class="left-down">Leaderboard</h5>
            <hr style="border:solid 2px #e0e0e0"></hr>     
            <br>  
            <p class="light">KorQuAD 1.0의 Test set으로 평가한 Exact Match(EM) 및 F1 score 입니다. </p>
            <br>
                <style>
                  table {
                    width: 100%;
                    border-color: #dddddd ;
                    border-top: 1px solid #dddddd;
                    border-collapse: collapse;               
                  }
                  th, td {
                    border-bottom: 1px solid #dddddd;
                    padding: 10px;
                  }
                  p {
                    border: 5px;
                    margin: 0px;
                  }
                </style>
                
                <table class="centered">
                  <thead>
                    <tr>
                        <th>Rank</th>
                        <th>Reg. Date</th>
                        <th>Model</th>
                        <th>EM</th>
                        <th>F1</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td bgcolor="#eee">-</td>
                      <td bgcolor="#eee">2018.10.17</td>
                      <td bgcolor="#eee">
                        <b>Human Performance</b>
                      </td>
                      <td bgcolor="#eee">80.17</td>
                      <td bgcolor="#eee">91.20</td>
                    </tr>
                    <tr>
                      <td>1</td>
                      <td>2020.01.08</td>
                      <td>SkERT-Large (single model)
                        <p class="light">Skelter Labs</p>
                      </td>
                      <td>87.66</td>
                      <td><b>95.15</b></td>
                    </tr>                      
                    <tr>
                      <td>2</td>
                      <td>2019.10.25</td>
                      <td>KorBERT-Large v1.0
                        <p class="light">ETRI ExoBrain Team</p>
                      </td>
                      <td><b>87.76</b></td>
                      <td>95.02</td>
                    </tr>
                    <tr>
                      <td>3</td>
                      <td>2020.01.07</td>
                      <td>SkERT-LARGE (single model)
                        <p class="light">Skelter Labs</p>
                      </td>
                      <td>87.25</td>
                      <td>94.75</td>
                    </tr>                      
                    <tr>
                      <td>4</td>
                      <td>2019.06.26</td>
                      <td>LaRva-Kor-Large+ + CLaF (single)
                        <p class="light">Clova AI LaRva Team</p>
                      </td>
                      <td>86.84</td>
                      <td>94.75</td>
                    </tr>
                    <tr>
                      <td>5</td>
                      <td>2020.01.03</td>
                      <td>SkERT Large (single model)
                        <p class="light">Skelter Labs</p>
                      </td>
                      <td>87.28</td>
                      <td>94.66</td>
                    </tr>
                    <tr>
                      <td>6</td>
                      <td>2019.06.04</td>
                      <td>BERT-CLKT-MIDDLE (single model)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>86.71</td>
                      <td>94.55</td>
                    </tr>
                    <tr>
                      <td>7</td>
                      <td>2019.06.03</td>
                      <td>LaRva-Kor-Large + CLaF (single)
                        <p class="light">Clova AI LaRva Team (LPT)</p>
                      </td>
                      <td>86.79</td>
                      <td>94.37</td>
                    </tr>
                    <tr>
                      <td>8</td>
                      <td>2020.01.02</td>
                      <td>SkERT-Large (single model)
                        <p class="light">Skelter Labs</p>
                      </td>
                      <td>86.30</td>
                      <td>94.28</td>
                    </tr>                      
                    <tr>
                      <td>9</td>
                      <td>2019.03.15</td>
                      <td>{BERT-CLKT} (single model)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>86.22</td>
                      <td>94.08</td>
                    </tr>
                    <tr>
                      <td>10</td>
                      <td>2019.07.17</td>
                      <td>KorBERT
                        <p class="light">Anonymous</p>
                      </td>
                      <td>86.12</td>
                      <td>94.02</td>
                    </tr>
                    <tr>
                      <td>11</td>
                      <td>2019.05.07</td>
                      <td>LaRva-Kor+ + CLaF (single)
                        <p class="light">Clova AI LaRva Team (LPT)</p>
                      </td>
                      <td>85.35</td>
                      <td>93.96</td>
                    </tr>
                    <tr>
                      <td>12</td>
                      <td>2019.04.24</td>
                      <td>LaRva-Kor+ (single)
                        <p class="light">Clova AI LaRva Team (LPT)</p>
                      </td>
                      <td>85.25</td>
                      <td>93.94</td>
                    </tr> 
                    <tr>
                      <td>13</td>
                      <td>2019.07.25</td>
                      <td>Bert-Base-Kor-LEN (ensemble)
                        <p class="light">ChangWook Jun</p>
                      </td>
                      <td>85.51</td>
                      <td>93.46</td>
                    </tr>                     
                    <tr>
                      <td>14</td>
                      <td>2019.06.29</td>
                      <td>BERT-DAL-Masking-Morp (single)
                        <p class="light">JunSeok Kim</p>
                      </td>
                      <td>85.15</td>
                      <td>93.20</td>
                    </tr>
                    <tr>
                      <td>15</td>
                      <td>2019.12.12</td>
                      <td>HanBert-54k-N (single model)
                        <p class="light">TwoBlock Ai</p>
                      </td>
                      <td>81.94</td>
                      <td>92.93</td>
                    </tr>                        
                    <tr>
                      <td>16</td>
                      <td>2019.09.20</td>
                      <td>ETRI BERT (single model)
                        <p class="light">deepfine</p>
                      </td>
                      <td>84.56</td>
                      <td>92.91</td>
                    </tr>
                    <tr>
                      <td>17</td>
                      <td>2019.05.24</td>
                      <td>BERT fine-tuned(ensemble)
                        <p class="light">Oh Yeon Taek</p>
                      </td>
                      <td>83.99</td>
                      <td>92.89</td>
                    </tr>                    
                    <tr>
                      <td>18</td>
                      <td>2019.12.19</td>
                      <td>HanBert-54k-ML (single model)
                        <p class="light">TwoBlock Ai</p>
                      </td>
                      <td>81.89</td>
                      <td>92.65</td>
                    </tr>                      
                    <tr>
                      <td>19</td>
                      <td>2019.06.19</td>
                      <td>ETRI BERT + Saltlux ADAM API (single model)
                        <p class="light">Saltlux Inc. AI Labs, AIR team</p>
                      </td>
                      <td>84.15</td>
                      <td>92.64</td>
                    </tr>
                    <tr>
                      <td>20</td>
                      <td>2019.04.10</td>
                      <td>BERT-Kor (single)
                        <p class="light">Clova AI LPT Team</p>
                      </td>
                      <td>83.79</td>
                      <td>92.63</td>
                    </tr>                       
                    <tr>
                      <td>21</td>
                      <td>2019.03.29</td>
                      <td>BERT insp. by GPT-2 + KHAIII (single)
                        <p class="light">Kakao NLP Team</p>
                      </td>
                      <td>84.12</td>
                      <td>92.62</td>
                    </tr> 
                    <tr>
                      <td>22</td>
                      <td>2019.06.19</td>
                      <td>BERT-DA-Masking-Morph (single)
                        <p class="light">JunSeok Kim</p>
                      </td>
                      <td>84.20</td>
                      <td>92.59</td>
                    </tr>
                    <tr>
                      <td>23</td>
                      <td>2019.12.20</td>
                      <td>HanBert-90k-N (single model)
                        <p class="light">TwoBlock Ai</p>
                      </td>
                      <td>81.61</td>
                      <td>92.48</td>
                    </tr>   
                    <tr>
                      <td>24</td>
                      <td>2019.12.20</td>
                      <td>HanBert-90k-ML (single model)
                        <p class="light">TwoBlock Ai</p>
                      </td>
                      <td>81.35</td>
                      <td>92.41</td>
                    </tr>                         
                    <tr>
                      <td>25</td>
                      <td>2019.09.10</td>
                      <td>ETRI BERT (single model)
                        <p class="light">deepfine</p>
                      </td>
                      <td>83.48</td>
                      <td>92.39</td>
                    </tr>                    
                    <tr>
                      <td>26</td>
                      <td>2019.04.01</td>
                      <td>BERT-Multilingual+CLAF+ReTK (single)
                        <p class="light">KIPI R&D Center1</p>
                      </td>
                      <td>83.76</td>
                      <td>92.27</td>
                    </tr>                    
                    <tr>
                      <td>27</td>
                      <td>2019.01.30</td>
                      <td>BERT LM fine-tuned + KHAIII + DHA (single)
                        <p class="light">Kakao NLP Team</p>
                      </td>
                      <td>83.32</td>
                      <td>92.10</td>
                    </tr>
                    <tr>
                      <td>28</td>
                      <td>2019.12.04</td>
                      <td>BERT+VA (single)
                        <p class="light">JoonOh-Oh</p>
                      </td>
                      <td>83.68</td>
                      <td>92.00</td>
                    </tr>                      
                    <tr>
                      <td>29</td>
                      <td>2019.01.24</td>
                      <td>BERT LM fine-tuned (single) + KHAIII
                        <p class="light">Kakao NLP Team</p>
                      </td>
                      <td>82.14</td>
                      <td>91.85</td>
                    </tr>
                    <tr>
                      <td>30</td>
                      <td>2019.01.30</td>
                      <td>BERT multilingual (ensemble)
                        <p class="light">mypeacefulcode</p>
                      </td>
                      <td>82.53</td>
                      <td>91.67</td>
                    </tr>
                    <tr>
                      <td>31</td>
                      <td>2019.03.28</td>
                      <td>BERT KOR (ensemble)
                        <p class="light">DeepNLP ONE Team</p>
                      </td>
                      <td>82.68</td>
                      <td>91.47</td>
                    </tr>
                    <tr>
                      <td>32</td>
                      <td>2019.06.13</td>
                      <td>{BERT-DA-Morph} (single)
                        <p class="light">JunSeok Kim</p>
                      </td>
                      <td>82.48</td>
                      <td>91.47</td>
                    </tr>
                    <tr>
                      <td>33</td>
                      <td>2019.06.03</td>
                      <td>DynamicConv + Self-Attention + N-gram masking (single) 
                        <p class="light">Enliple AI and Chonbuk National University, Cognitive Computing Lab</p>
                      </td>
                      <td>80.94</td>
                      <td>91.45</td>
                    </tr>
                    <tr>
                      <td>34</td>
                      <td>2019.06.03</td>
                      <td>BERT_LM_fine-tuned (single)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>82.04</td>
                      <td>91.40</td>
                    </tr>
                    <tr>
                      <td>35</td>
                      <td>2019.02.14</td>
                      <td>BERT fine-tuned (single) 
                        <p class="light">GIST-Dongju Park</p>
                      </td>
                      <td>82.27</td>
                      <td>91.24</td>
                    </tr>
                    <tr>
                      <td>36</td>
                      <td>2019.03.21</td>
                      <td>BERT+KEFT (single)
                        <p class="light">KT BigData BU</p>
                      </td>
                      <td>82.27</td>
                      <td>91.23</td>
                    </tr>
                    <tr>
                      <td>37</td>
                      <td>2019.12.01</td>
                      <td>BERT (single)
                        <p class="light">JoonOh-Oh</p>
                      </td>
                      <td>81.68</td>
                      <td>91.12</td>
                    </tr>                          
                    <tr>
                      <td>38</td>
                      <td>2019.02.22</td>
                      <td>BERT/RPST (single)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>82.25</td>
                      <td>91.11</td>
                    </tr>
                    <tr>
                      <td>39</td>
                      <td>2019.03.08</td>
                      <td>BERT + ES-Nori (single model)
                        <p class="light">Chang-Uk Jeong @ RNBSOFT AI Chatbot Team</p>
                      </td>
                      <td>81.94</td>
                      <td>91.04</td>
                    </tr>
                    <tr>
                      <td>40</td>
                      <td>2019.10.15</td>
                      <td>{BERT-base-unigramLM(Kudo)} (single model)
                        <p class="light">AIRI@domyounglee</p>
                      </td>
                      <td>78.55</td>
                      <td>91.04</td>
                    </tr>                          
                    <tr>
                      <td>41</td>
                      <td>2019.06.19</td>
                      <td>BERT-Kor-morph (single)
                        <p class="light">AIRI</p>
                      </td>
                      <td>80.09</td>
                      <td>91.01</td>
                    </tr>
                    <tr>
                      <td>42</td>
                      <td>2019.04.08</td>
                      <td>BERT (single)
                        <p class="light">Bnonymous</p>
                      </td>
                      <td>80.58</td>
                      <td>90.75</td>
                    </tr>
                    <tr>
                      <td>43</td>
                      <td>2019.01.10</td>
                      <td>EBB-Net + BERT (single model)
                        <p class="light">Enliple AI</p>
                      </td>
                      <td>80.12</td>
                      <td>90.71</td>
                    </tr>
                    <tr>
                      <td>44</td>
                      <td>2019.04.10</td>
                      <td>Bert single-model 
                        <p class="light">NerdFactory, AI research</p>
                      </td>
                      <td>81.63</td>
                      <td>90.68</td>
                    </tr>
                    <tr>
                      <td>45</td>
                      <td>2020.02.12</td>
                      <td>BERT-Multilingual (single model)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>81.09</td>
                      <td>90.61</td>
                    </tr>                        
                    <tr>
                      <td>46</td>
                      <td>2019.09.05</td>
                      <td>{ETRI BERT} (single model)
                        <p class="light">deepfine</p>
                      </td>
                      <td>80.86</td>
                      <td>90.61</td>
                    </tr>                          
                    <tr>
                      <td>47</td>
                      <td>2019.07.11</td>
                      <td>BERT-Fintent V1 + Utagger-UoU (single)
                        <p class="light">GDchain AI Lab</p>
                      </td>
                      <td>79.45</td>
                      <td>90.38</td>
                    </tr>                     
                    <tr>
                      <td>48</td>
                      <td>2019.03.13</td>
                      <td>BERT-Multilingual (single model)
                        <p class="light">Initiative</p>
                      </td>
                      <td>80.66</td>
                      <td>90.35</td>
                    </tr> 
                    <tr>
                      <td>49</td>
                      <td>2019.05.08</td>
                      <td>BERT-Multiling-morph (single)
                        <p class="light">kwonmha</p>
                      </td>
                      <td>79.35</td>
                      <td>90.34</td>
                    </tr>
                    <tr>
                      <td>50</td>
                      <td>2019.03.05</td>
                      <td>BERT-multilingual (single model)
                        <p class="light">HYU-Minho Ryu</p>
                      </td>
                      <td>80.45</td>
                      <td>90.27</td>
                    </tr>
                    <tr>
                      <td>51</td>
                      <td>2019.09.18</td>
                      <td>Mobile-BERT(18M Params & 36.6MB size) (single)
                        <p class="light">Enliple AI and Chonbuk National University, Cognitive Computing Lab</p>
                      </td>
                      <td>81.07</td>
                      <td>90.25</td>
                    </tr>                          
                    <tr>
                      <td>52</td>
                      <td>2019.02.21</td>
                      <td>Bert_FineTuning (Single model)
                        <p class="light">Star Ji</p>
                      </td>
                      <td>71.75</td>
                      <td>90.12</td>
                    </tr>
                    <tr>
                      <td>53</td>
                      <td>2019.05.08</td>
                      <td>BERT-Multi-Kr (single)
                        <p class="light">paul.kim</p>
                      </td>
                      <td>71.86</td>
                      <td>89.83</td>
                    </tr>
                    <tr>
                      <td>54</td>
                      <td>2019.03.26</td>
                      <td>BERT (single model)
                        <p class="light">BDOT</p>
                      </td>
                      <td>71.78</td>
                      <td>89.82</td>
                    </tr>
                    <tr>
                      <td>55</td>
                      <td>2019.06.17</td>
                      <td>BERT-Multilingual
                        <p class="light">lyeoni, NEOWIZ AI Lab</p>
                      </td>
                      <td>71.47</td>
                      <td>89.71</td>
                    </tr>
                    <tr>
                      <td>56</td>
                      <td>2020.02.17</td>
                      <td>{Bert_Multi} (multi model)
                        <p class="light">EunsongGoh</p>
                      </td>
                      <td>66.73</td>
                      <td>89.62</td>
                    </tr>                      
                    <tr>
                      <td>57</td>
                      <td>2019.04.29</td>
                      <td>BERT_Multi (Single)
                        <p class="light">EunsongGoh</p>
                      </td>
                      <td>71.40</td>
                      <td>89.49</td>
                    </tr>
                    <tr>
                      <td>58</td>
                      <td>2019.01.11</td>
                      <td>BERT-Multiling-simple (single)
                        <p class="light">kwonmha</p>
                      </td>
                      <td>70.75</td>
                      <td>89.44</td>
                    </tr>
                    <tr>
                      <td>59</td>
                      <td>2019.02.19</td>
                      <td>BERT multilingual finetune TPU (single)
                        <p class="light">jskim_kbnow</p>
                      </td>
                      <td>71.19</td>
                      <td>89.20</td>
                    </tr>  
                    <tr>
                      <td>60</td>
                      <td>2019.05.21</td>
                      <td>Bert-Base-Multilingual (Single)
                        <p class="light">ybigta KorQuAD</p>
                      </td>
                      <td>70.50</td>
                      <td>89.14</td>
                    </tr> 
                    <tr>
                      <td>61</td>
                      <td>2019.06.01</td>
                      <td>{BERT-Multilingual fine-tuned+OKT} (single)
                        <p class="light">JunSeok Kim</p>
                      </td>
                      <td>77.12</td>
                      <td>88.92</td>
                    </tr>  
                    <tr>
                      <td>62</td>
                      <td>2019.05.04</td>
                      <td>BERT-multilingual (single)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>70.57</td>
                      <td>88.64</td>
                    </tr>
                    <tr>
                      <td>63</td>
                      <td>2019.04.26</td>
                      <td>BERT-multilingual (single model)
                        <p class="light">Tae Hwan Jung@graykode, Kyung Hee Univ</p>
                      </td>
                      <td>69.86</td>
                      <td>88.49</td>
                    </tr>
                    <tr>
                      <td>64</td>
                      <td>2018.12.28</td>
                      <td>BERT-Multilingual (single)
                        <p class="light">Clova AI LPT Team</p>
                      </td>
                      <td>77.04</td>
                      <td>87.85</td>
                    </tr>
                    <tr>                      
                      <td>65</td>
                      <td>2019.03.04</td>
                      <td>DocQA (single)
                        <p class="light">CLaF</p>
                      </td>
                      <td>75.63</td>
                      <td>85.91</td>
                    </tr>
                    <tr>
                      <td>66</td>
                      <td>2019.12.20</td>
                      <td>DistilBERT-base-multilingual (default huggingface) (single model)
                        <p class="light">Heeryon Cho</p>
                      </td>
                      <td>66.88</td>
                      <td>85.72</td>
                    </tr>                      
                    <tr>
                      <td>67</td>
                      <td>2019.03.04</td>
                      <td>BiDAF (single)
                        <p class="light">CLaF</p>
                      </td>
                      <td>71.88</td>
                      <td>83.00</td>
                    </tr>
                    <tr>
                      <td>68</td>
                      <td>2019.12.19</td>
                      <td>DistilBERT-base-multilingual (from huggingface) (single model)
                        <p class="light">Anonymous</p>
                      </td>
                      <td>62.90</td>
                      <td>81.29</td>
                    </tr>                       
                    <tr>
                      <td bgcolor="#eee">-</td>
                      <td bgcolor="#eee">2018.10.17</td>
                      <td bgcolor="#eee">
                        <b>Baseline</b>
                      </td>
                      <td bgcolor="#eee">71.52</td>
                      <td bgcolor="#eee">82.99</td>
                    </tr>
                  </tbody>
                </table>
                <br><br><br>
          </div>
        </div>
      </div>
    </div>


      

<!--     <div style="background: #ddd">
    <div class="container last-post">
    <section>
        <h5>Latest Post</h5>
        <ul class="collection">
        {% for post in site.posts %}
        <li class="collection-item avatar">
          {% assign date_format = site.minima.date_format | default: "%m/%d" %}
          <div class="date-post">{{ post.date | date: date_format }}</div>
          <span class="title"><a class="post-link" href="{{ post.url | relative_url }}">{{ post.title | escape }}</a></span>
          <p>
             {{ post.content | truncatewords: 10 }}
          </p>
          <a href="{{ post.url | relative_url }}" class="secondary-content"><i class="material-icons">navigate_next</i></a>
        </li>
        {% endfor %}
        </ul>  
    </section> dd -->

  </div>

</div>
</main>
